
Obesity Risk Prediction using Machine Learning
Project Overview
This project developed a robust and interpretable machine learning system to predict individual obesity levels based on lifestyle, dietary habits, and demographic factors. The primary goal was to move beyond traditional, reactive measures like BMI by creating a predictive tool that can identify obesity risk early and provide clear, actionable insights into the contributing factors. The research was guided by three core questions about prediction accuracy, model fairness, and feature interpretability. The project followed a structured, industry-standard methodology to ensure the models are not only accurate but also reliable, fair, and transparent for potential use in healthcare and public health settings.

Research Questions and Findings
1. How accurately can machine learning models predict obesity?
This question was addressed by implementing and evaluating seven different machine learning algorithms, including ensemble methods, deep learning architectures, and traditional classifiers. The models were trained on comprehensive lifestyle and demographic data and evaluated using multiple performance metrics. XGBoost emerged as the most accurate model, achieving an exceptional accuracy of 98.63%, F1-score of 98.63%, and ROC-AUC of 99.95%. The confusion matrix analysis confirmed minimal misclassifications, with only rare errors between adjacent obesity categories. This demonstrates that machine learning models can predict obesity levels with remarkably high accuracy, significantly outperforming traditional assessment methods and providing a reliable tool for early risk identification.

2. How can the models be designed and evaluated to ensure fairness and avoid bias in predictions?
To address fairness concerns, the research incorporated specific fairness metrics into the model evaluation framework, focusing on gender as a protected attribute. We calculated True Positive Rate Difference (Equal Opportunity Difference) and Precision Difference (Demographic Parity Difference) to quantify prediction disparities across subgroups. The analysis revealed an important trade-off: while ensemble methods like XGBoost achieved the highest accuracy, deep learning models (LSTM and MLP) demonstrated better fairness with approximately 35% lower subgroup disparities. This finding underscores that model selection in healthcare applications must balance predictive performance with ethical considerations, and that fairness should be explicitly measured and considered alongside traditional performance metrics.

3. Which features in the dataset have the greatest impact on obesity predictions according to the model's explanations?
We employed Explainable AI (XAI) techniques, specifically SHAP and LIME, to interpret the model's decision-making process and identify the most influential features. The analysis revealed that weight and height were the strongest predictors across all obesity categories. Family history of overweight emerged as another critical factor, highlighting the genetic component of obesity. Behavioral factors including physical activity frequency, alcohol intake, and consumption patterns between meals also showed significant impact. The SHAP analysis provided both global feature importance rankings and local explanations for individual predictions, enabling healthcare practitioners to understand which specific factors drive each person's obesity risk assessment, thus supporting targeted intervention strategies.

Data Source and Preparation
The study utilized a comprehensive dataset sourced from the UCI Machine Learning Repository, comprising 2,111 individual records with 17 distinct attributes. This dataset included a mix of genuine responses from participants in Mexico, Peru, and Colombia, supplemented with synthetically generated data to ensure class balance. Key data preparation steps were meticulously executed to ensure data quality. This involved removing duplicate entries, renaming columns for better clarity (e.g., 'nobeyesdad' to 'Obesity_level'), and conducting extensive exploratory data analysis. Visualizations were created to understand the distribution of key features like gender, family history of obesity, consumption of high-calorie foods, and physical activity levels, revealing important patterns and correlations within the data.

Methodology and Modeling Approach
The entire project was structured around the CRISP-DM (Cross-Industry Standard Process for Data Mining) framework, ensuring a systematic and reproducible workflow. The process spanned from business understanding to model evaluation. Critical preprocessing steps included encoding categorical variables into a numerical format suitable for algorithms and addressing the inherent class imbalance in the target variable using SMOTENC, a technique effective for datasets with both categorical and numerical features. Feature selection was performed using three methods—Random Forest, OneR, and Mutual Information—to identify the most predictive variables, which led to the retention of 12 key features. A diverse set of machine learning models was then implemented and rigorously trained, including Logistic Regression, Random Forest, XGBoost, CatBoost, Multilayer Perceptron (MLP), LSTM, and a Stacked Ensemble model.

Model Evaluation and Selection
Each model was evaluated using a comprehensive suite of performance metrics, including accuracy, precision, recall, F1-score, and ROC-AUC. A critical aspect of the evaluation was the assessment of model fairness, where metrics like True Positive Rate Difference and Precision Difference were calculated to identify potential biases across gender subgroups. The results demonstrated that tree-based ensemble models, particularly XGBoost, achieved the highest predictive performance with an accuracy of 98.63% and an exceptional AUC of 99.95%. However, a notable trade-off was observed: while ensemble models like XGBoost had the highest accuracy, deep learning models (LSTM and MLP) exhibited better fairness with lower subgroup disparities. After a balanced consideration of both performance and fairness, XGBoost was selected as the final model due to its superior overall capability and minimal misclassifications.

Explainable AI and Interpretation
To ensure the model's predictions are transparent and trustworthy, Explainable AI (XAI) techniques were employed. SHAP (SHapley Additive exPlanations) was used to provide both global and local interpretations, quantifying the contribution of each feature (such as weight, height, and family history) to individual predictions. LIME (Local Interpretable Model-agnostic Explanations) complemented this by offering intuitive, local explanations for specific cases. These tools allow healthcare practitioners to understand the "why" behind a prediction, enabling them to validate the model's reasoning and focus on the most influential risk factors for each individual, thereby facilitating targeted interventions.

Conclusion and Impact
In conclusion, this project successfully addressed all three research questions by demonstrating that machine learning models can predict obesity with high accuracy, that fairness can be quantitatively evaluated and balanced against performance, and that explainable AI techniques can identify the most impactful risk factors. The final XGBoost model offers a powerful tool that can help healthcare professionals identify at-risk individuals earlier, understand the key lifestyle drivers of their condition, and ultimately contribute to more effective, personalized obesity prevention and management strategies. By integrating advanced modeling with explainable AI, the solution addresses the limitations of traditional methods by providing early risk detection and clear, interpretable insights, highlighting the importance of considering both accuracy and fairness in healthcare applications.
